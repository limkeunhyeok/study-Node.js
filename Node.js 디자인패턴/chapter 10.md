# Chapter 10 - 확장성과 구조적 패턴

## 1. 어플리케이션 확장에 대한 소개

### 1-1 Node.js 어플리케이션 확장

<p>
    일반적인 Node.js 어플리케이션의 대부분의 작업이 싱글 스레드의 컨텍스트에서 실행된다. 논 블로킹 I/O에 의해 완벽하게 활용되는 싱글 스레드는 초당 수백 개의 짧은 요청을 처리하는 어플리케이션에 유용하다. 상용 하드웨어를 사용한다고 가정하면 싱글 스레드가 지원할 수 있는 용량은 서버의 성능에 관계없이 제한적이다. 따라서 부하가 많은 어플리케이션에 Node.js를 사용하려는 경우 유일한 방법은 멀티 프로세스와 멀티 머신에 확장하는 것이다.
</p>

<p>
    확장을 통해 작업량 뿐만 아니라 장애에 대한 가용성과 내성 같은 특성을 얻을 수 있다. 확장성은 어플리케이션의 크기와 복잡성에도 적용할 수 있는 중요한 개념이며, 확장 가능한 아키텍처를 구축하는 것은 소프트웨어 설계 시 또 다른 중요 요소이다.
</p>

### 1-2 확장성의 세 가지 차원

<p>
    확장성에서 필요한 첫 번째 기본 원칙은 멀티 프로세스와 멀티 시스템으로 어플리케이션의 부하를 분할하는 부하 분산(load distribution)이다. 이를 달성하는 방법으로 'The Art of Scalability'라는 저서에서는 스케일 큐브(Scale Cube)라고 하는 독창적인 모델을 제시한다. 이 모델은 다음 세 가지 측면에서 확장성을 설명한다.
</p>

- x축: 복제
- y축: 서비스/기능별 분해
- z축: 데이터 파티션 분할

![1](https://user-images.githubusercontent.com/38815618/106353007-b9af9400-632a-11eb-87ce-bc93a8c16eef.PNG)

<p>
    큐브의 왼쪽 아래 모서리는 모든 기능과 서비스를 단일 코드 베이스로한, 단일 인스턴스에서 실행되는 어플리케이션을 나타낸다. 이는 작은 작업량을 처리하거나 개발 초기 단계의 어플리케이션에 공통적인 상황이다.
</p>

<p>
    x축을 따라 확장하는 것은 간단하고 저렴하며 매우 효과적이다. 이 기술 이면의 원리는 동일한 어플리케이션을 n번 복제하고 각 인스턴스가 작업량의 1/n씩을 처리하도록 하는 것이다.
</p>

<p>
    y축을 따라 확장하면 해당 기능, 서비스 또는 유스케이스에 따라 어플리케이션이 분해된다. 이 경우 분해(decomposing)는 각기 다른 코드 베이스가 있는 다른 독립 실행형 어플리케이션을 생성하는 것을 의미하며, 때로는 전용 데이터베이스 또는 별도의 UI를 사용하여 생성하기도 한다. 어플리케이션을 기능별로 분리하는 기준은 주로 비즈니스 요구 사항, use case, 데이터 및 기타 여러 요소에 따라 다르다. 이는 어플리케이션의 아키텍처뿐만 아니라 개발 관점에서 관리되는 방식에도 큰 영향을 미치는 확장성(scale)에 대한 또 하나의 관점이다.
</p>

<p>
    z축을 따라 확장하는 것은 어플리케이션의 각 인스턴스를 전체 데이터의 일부의 처리만을 담당하도록 분할하는 것이다. 이는 주로 데이터베이스에서 사용되는 기술이며 수평 분할 또는 샤딩(sharding)이라 불린다. 이 설정에서는 동일한 어플리케이션의 인스턴스가 여러 개 있으며, 각 인스턴스는 서로 다른 기준을 사용하여 결정되는 데이터 파티션에서 작동한다. 데이터 파티션을 사용하려면 어플리케이션의 어느 인스턴스가 주어진 데이터를 담당하는지 결정하기 위해 각 작업 앞에 조회 단계가 있어야 한다. 데이터 파티셔닝(partitioning)은 대개 거대한 단일 데이터셋을 처리하는 것과 관련한 문제를 극복하기 때문에 데이터베이스 단에서 적용되고 처리된다. 어플리케이션 수준에서 이를 적용하는 것은 복잡하고 분산된 아키텍처 또는 매우 특별한 사용 사례에 대해서만 고려해 볼 가치가 있다. 복잡성을 감안할 때, z축을 따라 확장하는 것은 x, y축을 완전히 활용한 후에만 고려해야 한다.
</p>

## 2. 복제 및 로드 밸런싱

<p>
    전통적으로 멀티스레드 웹 서버는 일반적으로 시스템에 할당된 자원을 더 이상 업그레이드할 수 없거나, 단순히 다른 시스템을 도입하는 것보다 업그레이드에 더 많은 비용이 소요될 경우 확장된다. 멀티스레드를 사용함으로써 기존 웹 서버는 사용 가능한 모든 프로세서와 메모리를 사용하여 서버의 모든 처리 성능을 활용할 수 있다. 하지만 단일 Node.js 프로세스는 싱글스레드로 실행되고, 기본적으로 64비트 시스템에서는 1.7GB의 메모리 제한이 있다. 즉, Node.js 어플리케이션은 일반적으로 단일 시스템의 컨텍스트에서 조차 기존 웹 서버와 비교하여 모든 자원을 활용할 수 있도록 하기 위해 훨씬 빠르게 확장의 필요성이 대두된다.
</p>

<p>
    복제로 Node.js 어플리케이션을 확장하는 것은 비교적 간단해서 중복된 장애 방지 설정을 위해 더 많은 리소스를 확보할 필요가 없는 경우에도 구현되는 경우가 많다.
</p>

<p>
    이렇게 하면 개발자가 어플리케이션의 초기 단계에서 확장성을 고려하게 되어 어플리케이션이 여러 프로세스 또는 시스템에서 공유될 수 없는 리소스에 의존하지 않게 된다. 실제로 어플리케이션을 확장하기 위한 절대적인 전제 조건은 각 인스턴스가 공유할 수 없는 자원에 콩통 정보를 저장할 필요가 없어야 한다는 것이다.
</p>

### 2-1 클러스터 모듈

![1](https://user-images.githubusercontent.com/38815618/106360144-2b530680-635a-11eb-95b5-a5317a397fd4.PNG)

<p>
    Node.js에서 단일 시스템에서 실행되는 여러 개의 인스턴스 간에 어플리케이션의 부하를 분배하는 가장 간단한 패턴은 코어 라이브러리의 일부인 클러스터 모듈을 사용하는 것이다. 클러스터 모듈은 다음 그림과 같이 동일한 어플리케이션의 새 인스턴스를 간단하게 포킹(forking)하고 들어오는 연결을 자동으로 여러 인스턴스에 분산시킨다.
</p>

<p>
    마스터 프로세스는 확장하고자 하는 각 어플리케이션의 인스턴스를 나타내는 여러 프로세스를 생성한다. 들어오는 각 연결은 복제된 작업자들에게 나뉘어져 부하를 분산시킨다.
</p>

#### 클러스터 모듈의 동작에 대한 참고 사항

<p>
    Node.js 0.8 및 0.10 미만에서는 클러스터 모듈이 작업자 간에 동일한 서버 소켓을 공유하고 사용 가능한 작업자 간에 들어오는 연결의 로드 밸런싱 작업을 운영체제에 맡긴다. 이러한 방식은 사실, 운영체제가 작업자에게 부하를 분산시키기 위해 사용하는 알고리즘은 네트워크 요청을 로드 밸런싱하는 것이 아니라 프로세스의 실행을 예약하는 것이다. 결과적으로, 부하가 모든 인스턴스에 걸쳐 항상 균일하지 않다. 대개 일부 작업자가 대부분의 부하를 받는다. 이러한 유형의 동작은 서로 다른 프로세스 사이의 컨텍스트 전환을 최소화하는데 초점을 맞추기 때문에 운영체제 스케줄러에게는 적합할 수 있다. 간단히 말해 클러스터 모듈은 최대한의 잠재력을 발휘하지 못한다.
</p>

<p>
    이후의 버전에서는 명시적 라운드 로빈 로드 밸런스 알고리즘이 마스터 프로세스 내부에 포함되어 요청이 모든 작업자들에게 균등하게 배분된다. 새로운 로드 밸런스 알고리즘은 기본적으로 windows를 제외한 모든 플랫폼에서 사용 가능하다.
</p>

#### 간단한 HTTP 서버 만들기

```javascript
// app.js
const http = require('http');
const pid = process.pid;

http.createServer((req, res) => {
    for (let i = 1e7; i > 0; i--) {}
    console.log(`Handling request from ${pid}`);
    res.end(`Hello from ${pid}\n`);
}).listen(8080, () => {
    console.log(`Started ${pid}`);
});
```

<p>
    HTTP 서버는 PID가 포함된 메시지를 다시 전송하여 모든 요청에 응답한다. 이는 어떤 어플리케이션 인스턴스가 요청을 처리하는지 확인하는데 유용할 것이다. 또한 실제 CPU 작업을 시뮬레이션하기 위해 빈 루프를 천만번 수행한다. 이를 실행하고 네트워크 벤치마킹 도구를 사용하여, 서버가 하나의 프로세스만 사용하여 처리할 수 있는 초당 요청양을 측정할 수 있다.
</p>

#### 클러스터 모듈을 사용한 확장

```javascript
// clusteredApp.js
const cluster = require('cluster');
const os = require('os');

if(cluster.isMaster) {
    const cpus = os.cpus().length;
    for (let i = 0; i < cpus; i++) { // 1.
        cluster.fork();
    }
} else {
    require('./app'); // 2.
}
```

1. 커맨드 라인에서 clusteredApp을 실행하면 마스터 프로세스가 실행된다. cluster.isMaster 변수는 true로 설정되어 있으며 `cluster.fork()`를 사용하여 현재 프로세스를 포킹해야 한다. 앞의 예제에서 사용 가능한 처리 성능을 모두 활용하기 위해 시스템 CPU 수만큼 작업자를 실행한다.
2. 마스터 프로세스에서 `cluster.fork()`를 실행하면 현재 메인 모듈이 다시 실행되지만 이번에는 작업자 모드로 실행된다. 어플리케이션이 작업자로 실행되면 실제 작업을 시작할 수 있다. 이 예제에서는 실제로 새로운 HTTP 서버를 시작하는 app 모듈을 로드한다.

<p>
    이를 실행하면 각 요청에 대해 다른 PID를 가진 메시지를 반환한다. 즉, 요청이 다른 작업자에 의해 처리되어 부하가 분산되었다. 이렇게 하면 멀티 프로세스에서 어플리케이션을 확장하여 얻는 성능 향상을 발견할 수 있다. 만약 4개의 프로세서가 있는 리눅스 시스템에서 Node.js 6을 사용하면 평균 CPU 로드가 90%로 성능 향상이 약 3배가 된다.
</p>

#### 클러스터 모듈을 통한 복원성 및 가용성

<p>
    어플리케이션을 확장하는 것은 특히 오작동이나 갑작스러운 정지가 발생하는 상황에서도 일정한 수준의 서비스를 유지하는 능력과 같은 다른 이점을 가져올 수 있다. 이 속성을 복원성이라고 하며 시스템 가용성에 기여한다.
</p>

<p>
    동일한 어플리케이션의 여러 인스턴스를 시작함으로써 중복 시스템을 생성한다. 즉, 어떤 이유로든 하나의 인스턴스가 중단되더라도 요청을 처리할 수 있는 다른 인스턴스가 여전히 준비되어 있음을 의미한다.
</p>

<p>
    예제를 위해 app.js에 setTimeout과 Error 객체를 이용하여 일정 시간 후에 정지하도록 수정한다. 그 뒤 클러스터 모듈을 사용하여 작업자가 오류 코드로 종료되는 것을 감지하는 새로운 작업자를 생성한다.
</p>

```javascript
if (cluster.isMaster) {
    // ...

    cluster.on('exit', (worker, code) => {
        if (code != 0 && !worker.suicide) {
            console.log('Worker crashed. Starting a new worker');
            cluster.fork();
        }
    });
} else {
    require('./app');
}
```

<p>
    위의 코드는 마스터 프로세스가 exit 이벤트를 받자마자 프로세스가 의도적으로 종료되었는지, 에러로 종류되었는지 확인한다. 오류로 프로세스가 종료되었다면 새로운 작업자를 시작한다. 갑자기 종료된 작업자가 다시 시작되는 동안 다른 작업자가 요청을 계속 처리할 수 있으므로 어플리케이션의 가용성에는 영향을 미치지 않는다.
</p>

#### 다운타임이 없는(Zero-downtime) 재시작

<p>
    Node.js 어플리케이션 코드를 업데이트하면 다시 시작해야 할 수도 있다. 따라서  여러 인스턴스를 사용하면 어플리케이션의 가용성을 유지하는데 도움이 될 수 있다. 의도적으로 어플리케이션을 다시 시작하여 업데이트해야 할 경우, 다시 시작되고 요청을 처리할 수 없는 짧은 간격이 발생한다. 이에 해결책은 어플리케이션의 코드가 가용성에 영향을 미치지 않고 업데이트되도록 다운타임이 없는 재시작을 구현하는 것이다.
</p>

```javascript
// clusterApp.js

// ...

if (cluster.isMaster) {
  // ...
  
    process.on('SIGUSR2', () => { // 1.
        console.log('Restarting workers');
        const workers = Object.keys(cluster.workers);
        
        function restartWorker(i) { // 2.
            if (i >= workers.length) return;
            const worker = cluster.workers[workers[i]];
            console.log(`Stopping worker: ${worker.process.pid}`);
            worker.disconnect(); // 3.
            
            worker.on('exit', () => {
                if (!worker.suicide) return;
                const newWorker = cluster.fork(); // 4.
                newWorker.on('listening', () => {
                    restartWorker(i + 1); // 5.
                });
            });
        }
        restartWorker(0);
    });
} else {
    require('./app');
}
```

1. 작업자의 재시작은 SIGUSR2 시그널 수신 시 시작된다.
2. `restartWorker()`라는 반복 함수를 정의한다. 이는 cluster.workers 객체의 항목에 대해 비동기 순차 반복 패턴을 사용하여 구현한다.
3. `restartWorker()` 함수의 첫 번째 작업은 `worker.disconnect()`를 호출하여 작업자를 정상적으로 중지하는 것이다.
4. 종료된 프로세스가 제거되면 새로운 작업자를 생성할 수 있다.
5. 새로운 작업자가 준비되고 새로운 연결에 대한 listen이 준비되면, 반복의 다음 단계를 호출하여 다음 작업자를 재시작하는 작업을 계속적으로 진행한다.

### 2-2 상태 저장 통신(stateful communication) 다루기

<p>
    어플리케이션에 의해 유지되는 상태가 다양한 인스턴스 간에 공유되지 않는 상태 저장(stateful) 통신에서는 클러스터 모듈이 제대로 동작하지 않는다. 이는 동일한 상태 저장 세션에 속하는 다른 요청이 다른 어플리케이션 인스턴스에 의해 처리될 수 있기 때문이다.
</p>

![1](https://user-images.githubusercontent.com/38815618/106413964-c9e08400-648e-11eb-9772-2a22dac345a2.PNG)

<p>
    사용자 John은 처음에 어플리케이션에 자신을 인증해달라고 요청을 보내지만, 자신의 결과가 로컬(예: 메모리)에 저장된다. 따라서 인증 요청(인스턴스 A)을 받는 어플리케이션의 인스턴스에서만 John이 성공적으로 인증한 것을 인식하게 된다. John이 새로운 요청을 보내면 로드 밸런서는 이를 John의 인증 정보가 없는 다른 어플리케이션 인스턴스로 요청을 전달할 수 있으므로, 작업의 수행이 거부된다. 이를 해결하기 위해 적용할 수 있는 간단한 두 가지 솔루션이 있다.
</p>

#### 여러 인스턴스에서의 상태 공유

<p>
    상태 저장 통신을 사용하여 어플리케이션을 확장해야 하는 첫 번째 옵션은 모든 인스턴스에서 상태를 공유하는 것이다. 이러한 기능은 PostgreSQL, MongoDB 또는 CouchDB와 같은 공유 데이터베이스 저장소를 사용하여 쉽게 얻을 수 있다.
</p>

![2](https://user-images.githubusercontent.com/38815618/106413967-cb11b100-648e-11eb-8168-dacf9aa6cf7e.PNG)

<p>
    공유 저장소를 통신 상태의 저장에 사용할 때 유일한 단점은 항상 가능하지 않다는 것이다. 예를 들어, 메모리에 통신 상태를 저장하는 기존의 라이브러리를 계속 사용해야 하는 상황에 있을 수 있다. 어쨌든 기존의 어플리케이션이 있는 경우 이 솔루션을 적용하려면 어플리케이션의 코드를 변경해야 한다.
</p>

#### 고정 로드 밸런싱

<p>
    상태 저장 통신을 지원하기 위해 필요한 다른 대안은 로드 밸런사가 항상 세션과 관련된 모든 요청을 동일한 어플리케이션 인스턴스로 라우팅하도록 하는 것이다. 이 기술은 고정 로드 밸런싱(sticky load balancing)이라고도 한다.
</p>

![3](https://user-images.githubusercontent.com/38815618/106413968-cbaa4780-648e-11eb-9f75-02ab3e06753c.PNG)

<p>
    로드 밸런서는 새로운 세션과 관련된 요청을 받으면 로드 밸런싱 알고리즘에 의해 선택된 특정 인스턴스와의 맵을 만든다. 다음 번에 로드 밸런서가 동일한 세션에서 요청을 수신하면 이전에 세션과 연관된 어플리케이션 인스턴스를 선택하여 로드 밸런싱 알고리즘을 무시한다.
</p>

<p>
    상태 저장 연결을 하나의 서버에 연결하는 더 간단한 방법은 요청을 수행하는 클라이언트의 IP 주소를 사용하는 것이다. 일반적으로 IP는 요청을 수신하도록 지정된 어플리케이션 인스턴스를 나타내는 ID를 생성하기 위해 해시 함수에 전달된다. 이 기술은 로드 밸런서가 연결을 기억하지 않아도 되는 장점이 있다. 하지만 IP를 자주 변경하는 장치와는 제대로 작동하지 않는다.
</p>

<p>
    고정 로드 밸런싱의 가장 큰 문제는 어플리케이션의 모든 인스턴스가 동일하고, 한 인스턴스가 작업이 중단되면 다른 인스턴스가 이를 대체할 경우 시스템 이중화가 가지는 대부분의 장점이 사라진다는 것이다. 이러한 이유로 될 수 있으면 고정 로드 밸런싱을 피하고, 공유 저장소에서 세션 상태를 유지하거나 상태 저장 통신이 전혀 필요하지 않는 어플리케이션을 만드는 것이 선호된다.
</p>

### 2-3 역방향 프록시를 사용하여 확장

<p>
    클러스터 모듈이 Node.js 웹 어플리케이션 확장을 위한 유일한 옵션은 아니다. 사실 고가용성 운용 환경에서는 더 많은 제어와 성능을 제공하는 전통적인 기법이 더 선호되는 경우가 많다.
</p>

<p>
    클러스터를 사용하는 대신 다른 포트나 시스템에서 실행 중인 동일한 어플리케이션의 독립 실행형 인스턴스를 여러 개 시작한 다음, 역방향 프록시(reverse proxy 또는 gateway)를 사용하여 해당 인스턴스에 액세스하여 트래픽을 분산시킬 수 있다. 이 구성에서는 마스터 프로세스가 일련의 작업자들에게 요청을 배분하지 않고, 서로 다른 프로세스로 동일한 시스템에서 실행되거나 네트워크 내의 분산되어 있는 다른 프로세스들에 요청을 배포한다. 어플리케이션에 단일 액세스 지점을 제공하기 위해 역방향 프록시를 사용할 수 있다. 역방향 프록시는 클라이언트와 어플리케이션의 인스턴스 사이에 위치한 특수 디바이스 혹은 서비스로 모든 요청을 받아 대상 서버에 전달하고, 그 결과를 클라이언트에 반환한다. 이 시나리오에서 역방향 프록시는 어플리케이션 인스턴스 간에 요청을 분산시키는 로드 밸런서로도 사용된다.
</p>

![4](https://user-images.githubusercontent.com/38815618/106413969-cbaa4780-648e-11eb-85a7-954bb00d8db2.PNG)

<p>
    Node.js 어플리케이션에서 cluster 모듈 대신 이 방법을 선택하는 다음의 이유가 있다.
</p>

- 역방향 프록시는 여러 프로세스뿐만 아니라, 여러 시스템에 부하를 분산시킬 수 있다.
- 시장에서 인기있는 역방향 프록시는 대부분 고정 로드 밸런싱을 지원한다.
- 역방향 프록시는 프로그래밍 언어 또는 플랫폼에 관계없이 들어온 요청을 사용 가능한 서버로 라우팅할 수 있다.
- 보다 강력한 로드 밸런싱 알고리즘을 선택할 수 있다.
- 많은 역 프록시들이 URL 재작성, 캐싱, SSL 종단점과 같은 다른 서비스들을 제공하며, 심지어 정적 파일을 서비스하는데 사용될 수 있는 완전한 웹 서버의 기능도 제공한다.

<p>
    필요한 경우 클러스터 모듈을 역방향 프록시와 쉽게 결합할 수 있다. 역방향 프록시를 사용하는 로드 밸런서를 구현하는데는 여러 가지 옵션이 있으며, 일반적인 해결 방법은 다음과 같다.
</p>

- Nginx: 비 차단 I/O 모델을 기반으로 구축된 웹 서버, 역방향 프록시 및 로드 밸런서이다.
- HAProxy: TCP/HTTP 트래픽
- Node.js 기반 프록시: Node.js로 역방향 프록시와 로드 밸런서를 직접 구현할 수 있는 수 많은 방법이 있다.
- 클라우드 기반 프록시: 클라우드 컴퓨팅 시대에 서비스 형 로드 밸런서를 활용하는 것이 드문 일은 아니다. 이는 유지 관리가 거의 필요 없으며, 확장성이 매우 뛰어나고, 주문형 확장을 위한 동적 구성을 지원할 수 있다.

#### Nginx로 로드 밸런싱하기

<p>
    서버의 여러 인스턴스를 시작하는데 클러스터를 사용하지 않으므로, 커맨드 라인을 통해 수신 대기 포트를 인자로 받아들여 지정할 수 있도록 어플리케이션의 코드를 수정해야 한다.
</p>

```javascript
const http = require('http');
const pid = process.pid;

http.createServer((req, res) => {
    for (let i = 1e7; i > 0; i--) {}
    console.log(`Handling request from ${pid}`);
    res.end(`Hello from ${pid}\n`);
}).listen(process.env.PORT || process.argv[2] || 8080, () => {
    console.log(`Started ${pid}`);
});
```

<p>
    클러스터를 사용하지 않을 경우 부족한 또 다른 중요한 기능은 충돌이 발생할 경우 자동으로 다시 시작하는 것이다. 이는 어플리케이션을 모니터링하고 필요한 경우 재시작하는 외부 프로세스인 전용 수퍼바이저를 사용하여 쉽게 해결할 수 있다. 이를 위한 항목은 다음과 같다.
</p>

- Node.js 기반의 수퍼바이저인 forever 또는 pm2
- OS 기반의 모니터 upstart 또는 runit
- monit 또는 supervisor

<p>
    해당 예제를 위해 forever를 사용한다. 다음은 어플리케이션의 4개 인스턴스를 모두 다른 포트에서 시작하고 forever로 감시하는 것이다.
</p>

```bash
forever start app.js 8081
forever start app.js 8082
forever start app.js 8083
forever start app.js 8084
```

<p>
    Ngix 서버를 로드 밸런서로 설정하기 위해 ngix.conf를 사용한다.
</p>

```config
http {
    # [...]
    
    upstream nodejs_design_patterns_app {
        server 127.0.0.1:8081;
        server 127.0.0.1:8082;
        server 127.0.0.1:8083;
        server 127.0.0.1:8084;
    }

    # [...]
    
    server {
        listen 80;

        location / {
            proxy_pass http://nodejs_design_patterns_app;
        }
    }
    
    # [...]
}
```

<p>
    코드의 upstream nodejs_design_patterns_app 영역에서 네트워크 요청을 처리하는데 사용되는 백엔드 서버 목록을 정의한 다음 server 영역에서 proxy_pass를 지정한다. 이 지정문은 기본적으로 Nginx에게 정의한 서버 그룹에 요청을 전달하도록 한다.
</p>

### 2-4 서비스 레지스트리(service registry)

<p>
    최신 클라우드 기반 인프라의 한 가지 중요한 이점은 현재 또는 예측된 트래픽을 기반으로 어플리케이션의 용량을 동적으로 조정할 수 있다는 것이다. 이를 동적 스케일링(dynamic scaling)이라고 한다. 이러한 방식은 어플리케이션의 가용성과 응답성을 유지하면서 IT 이늪라의 비용을 엄청나게 줄일 수 있다.
</p>

<p>
    해당 개념은 어플리케이션의 트래픽이 최고조에 달해 성능의 저하가 발생하면 증가된 부하에 대처하기 위해 새 서버가 자동으로 생성되며, 특정 시간 동안 일부 서버를 종료할 수도 있다. 이 메커니즘을 사용하면 로드 밸런서가 항상 서버가 작동하는 시간을 알기 위해, 현재 네트워크 토폴로지에 대해 최신 상태를 유지해야 한다. 이러한 문제를 해결하기 위한 일반적인 패턴은 실행중인 서버와 해당 서버가 제공하는 서비스를 추적하는 서비스 레지스트리라는 중앙 저장소를 사용한다.
</p>

![1](https://user-images.githubusercontent.com/38815618/106561831-c4596b80-656c-11eb-966a-a83e8a4b2616.PNG)

<p>
    위 아키텍처는 API와 WebAp 두 가지 서비스가 있다고 가정한다. 로드 밸런서는 엔드포인트인 /api에 도착하는 요청들을 API 서비스를 구현한 모든 서버에 분배하고, 나머지 요청들은 WebApp 서비스를 구현한 서버에 분산시킨다. 로드 밸런서는 레지스트리를 사용하여 서버 목록을 얻게 된다.
</p>

<p>
    각 어플리케이션 인스턴스는 각자 온라인이 되는 순간에 자신을 서비스 레지스트리에 등록하고 중단될 때는 등록을 취소해야 한다. 이렇게 하면 로드 밸런서는 항상 네트워크에서 사용할 수 있는 서버 및 서비스에 대한 최신 정보를 가질 수 있다. 이 패턴은 로드 밸런싱 뿐만 아니라, 더 일반적으로는 서버에서 제공하느 서비스 유형을 분리하는 방법으로도 사용할 수 있다.
</p>

#### http-proxy와 consul을 사용한 동적 로드 밸런싱 구현

<p>
    Node.js 만을 사용하여 로드 밸런서를 구축하면 훨씬 더 많은 자유와 성능을 얻을 수 있으며, 서비스 레지스트리를 포함한 사용자 정의 로드 밸런싱 장치에 어떠한 유형의 패턴이나 알고리즘도 바로 구현할 수 있다. 다음 예제는 클러스터와 Nginx를 터스트하기 위해 사용한 것과 같은 간단한 HTTP 서버지만, 이번에는 각 서버가 시작하는 순간 서비스 레지스트리에 등록한다.
</p>

```javascript
// app.js
const http = require('http');
const pid = process.pid;
const consul = require('consul')();
const portfinder = require('portfinder');
const serviceType = process.argv[2];

portfinder.getPort((err, port) => { // 1.
    const serviceId = serviceType+port;
    consul.agent.service.register({ // 2.
        id: serviceId,
        name: serviceType,
        address: 'localhost',
        port: port,
        tags: [serviceType]
    }, () => {

        const unregisterService = (err) => { // 3.
            consul.agent.service.deregister(serviceId, () => {
                process.exit(err ? 1 : 0);
            });
        };

        process.on('exit', unregisterService); // 4.
        process.on('SIGINT', unregisterService);
        process.on('uncaughtException', unregisterService);

        http.createServer((req, res) => { // 5.
            for (let i = 1e7; i > 0; i--) {}
            console.log(`Handling request from ${pid}`);
            res.end(`${serviceType} response from ${pid}\n`);
        }).listen(port, () => {
            console.log(`Started ${serviceType} (${pid}) on port ${port}`);
        });
    });
});
```

- http-proxy: Node.js에 프록시와 로드 밸런서를 간단하게 생성할 수 있는 라이브러리
- portfinder: 시스템의 빈 포트를 발견할 수 있는 라이브러리
- consul: 서비스 등록을 허용하는 라이브러리

1. 먼저 portfinder.getPort를 사용하여 시스템의 빈 포트를 찾는다(기본적으로 8000부터 검색).
2. 다음으로 Consul 라이브러리를 사용하여 레지스트리에 새 서비스를 등록한다. 서비스 정의에는 id, name, address와 port, tag같은 일련의 속성이 필요하다. 이렇게 하면 cluster에서 사용할 수 있는 동일한 유형의 모든 서비스를 식별할 수 있다.
3. 여기서 Consul에 방금 등록한 서비스를 제거할 수 있는 unregisterService라는 함수를 정의한다.
4. unregisterService를 정리를 위한 함수로 사용하여 프로그램이 닫힐 때 서비스가 Consul에서 등록 해지되도록 한다.
5. 마지막으로 portfinder가 발견한 포트에서 서비스를 위한 HTTP 서버를 시작한다.

```javascript
// loadBalancer.js - 1
const routing = [
  {
    path: '/api',
    service: 'api-service',
    index: 0
  },
  {
    path: '/',
    service: 'webapp-service',
    index: 0
  }
];
```

<p>
    위의 코드는 먼저 uRL 경로를 서비스에 매핑하는 라우팅 테이블을 정의하였다. 라우팅 배열의 각 항목에는 매핑된 경로로 들어오는 요청을 처리하는데 사용되는 서비스가 포함되어 있다. index 속성은 지정된 서비스의 요청을 라운드 로빈하는데 사용된다.
</p>

```javascript
// loadBalancer.js - 2
const http = require('http');
const httpProxy = require('http-proxy');
const consul = require('consul')(); // 1.

const proxy = httpProxy.createProxyServer({});
http.createServer((req, res) => {
    let route;
    routing.some(entry => { // 2.
        route = entry;
        // route path를 시작하는지 체크
        return req.url.indexOf(route.path) === 0;
    });

    consul.agent.service.list((err, services) => { // 3.
        const servers = [];
        Object.keys(services).filter(id => {
            if (services[id].Tags.indexOf(route.service) > -1) {
                servers.push(`http://${services[id].Address}:${services[id].Port}`)
            }
        });

        if (!servers.length) {
            res.writeHead(502);
            return res.end('Bad gateway');
        }

        route.index = (route.index + 1) % servers.length; // 4.
        proxy.web(req, res, {target: servers[route.index]});
    });
}).listen(8080, () => console.log('Load balancer started on port 8080'));
```

1. 레지스트리에 접근하기 위해 consul을 불러온다. 다음으로 http-proxy 객체를 인스턴스화하고 일반 웹 서버를 시작한다.
2. 서버의 요청 핸들러에서 가장 먼저 수행해야 할 작업은 URL을 라우팅 테이블과 비교하는 것이다. 결과는 서비스 이름을 포함하는 기술자(descriptor)가 된다.
3. Consul로부터 필요한 서비스가 구현된 서비스들의 목록을 얻는다. 만약 이 목록이 비어있으면 클라이언트에 에러를 반환한다. tag 속성을 사용하여 사용 가능한 모든 서비스에서 현재 서비스 유형을 구현한 서버의 주소를 찾는다.
4. 끝으로 요청을 목적지로 라우팅한다. 라운드 로빈 방식에 따라 route.index를 목록의 다음 서버를 가리키도록 업데이트한다. 그런 다음 인덱스를 사용하여 목록에서 서버를 선택하여 요청 및 응답 개체와 함께 `proxy.web()`으로 전달한다. 그러면 선택한 서버로 요청이 전달된다.

<p>
    이 패턴의 장점은 즉각적이라는 것이다. 피룡에 따라 또는 일정에 따라 인프라를 동적으로 바로 확장할 수 있으며, 로드 밸런서는 별도의 추가 작업 없이 새로운 구성에 따라 자동으로 조정된다.
</p>

### 2-5 피어-투-피어 로드 밸런싱(peer-to-peer load balancing)

<p>
    역방향 프록시의 사용은 복잡한 내부 네트워크 아키텍쳐를 인터넷과 같은 공용 네트워크 영역에 공개하고자 할 때 거의 필수적이다. 복잡성을 숨기고 외부 어플리케이션이 쉽게 사용하고 참조할 수 있는 유일한 접근점을 제공한다. 그러나 내부용으로만 서비스를 확장해야 하는 경우 더 많은 유연성과 제어 기능을 제공할 수 있다.
</p>

<p>
    이러한 기능을 구현하기 위해 서비스 B에 의존하는 서비스 A가 있다고 가정해보면, 서비스 B는 여러 컴퓨터에 걸쳐 확장되며 내부 네트워크에서만 사용할 수 있다. 지금까지 배웠던 것은 서비스 A가 서비스 B를 구현하는 모든 서버에 트래픽을 배분하는 역방향 프록시를 사용하여 서비스 B에 연결한다는 것이다.
</p>

<p>
    이에 대안은 역방향 프록시를 제거하고 요청을 클라이언트에서 직접 배분하는 것이다. Service A는 Service B의 다양한 인스턴스 간의 연결에 대한 로드 밸런싱을 직접 담당한다. 이는 Service A가 Service B의 동작중인 서버에 대한 세부적인 정보를 알고 있고, 내부 네트워크에서 일반적으로 알려진 정보인 경우에만 가능하다. 이 접근 방식은 근본적으로 피어-투-피어 로드 밸런싱을 구현한다.
</p>

![2](https://user-images.githubusercontent.com/38815618/106561836-c58a9880-656c-11eb-89a5-342ba59f96cc.PNG)

<p>
    병목 현상이나 단일 접속점이 실패한 경우에 대한 걱정 없이 진정한 분산 통신을 가능하게 하는 매우 간단하고 효과적인 패턴이다. 또한 다음 이점이 있다.
</p>

- 네트워크 노드를 제거하여 인프라의 복잡성을 줄인다.
- 더 적은 노드를 통해 메시지가 전달되기 때문에 더 빠른 통신이 가능하다.
- 로드 밸런서가 처리할 수 있는 성능으로 인해 성능이 제한되지 않기 때문에 확장성이 좋다.

<p>
    반대로 역방향 프록시를 제거하면 실제로 기본 인프라의 복잡성이 노출된다. 또한 각 클라이언트는 로드 밸런싱 알고리즘을 구현하고 매일 변경될 수도 있는 인프라에 대한 정보를 최신 상태로 유지할 수 있어야 한다.
</p>

#### 여러 서버에 대해 요청을 분산할 수 있는 HTTP 클라이언트 구현

```javascript
// balanceRequest.js
const http = require('http');
const servers = [
    {host: 'localhost', port: '8081'},
    {host: 'localhost', port: '8082'}
];

let i = 0;

module.exports = (options, callback) => {
    i = (i + 1) % servers.length;
    options.hostname = servers[i].host;
    options.port = servers[i].port;
    
    return http.request(options, callback);
};
```

<p>
    위의 코드는 라운드 로빈 알고리즘을 사용하여 사용 가능한 서버 목록에서 선택한 서버에 맞도록 요청의 호스트 이름 및 포트를 재정의하도록 원래 http.request API를 래핑하였다. 그러면 래핑된 API를 다음과 같이 원활하게 사용할 수 있다.
</p>

```javascript
// client.js
const request = require('./balancedRequest');

for (let i = 10; i >= 0; i--) {
    request({method: 'GET', path: '/'}, res => {
        let str = '';
        res.on('data', chunk => {
                str += chunk;
        }).on('end', () => {
            console.log(str)
        });
    }).end();
}
```

<p>
    코드를 실행하기 위해서는 제공된 샘플 서버의 인스턴스 두 개를 시작해야 한다. 어플리케이션을 실행하면 각 요청이 다른 서버로 전송되는 방식을 확인하여 이제 전용 역방향 프록시 없이도 로드 밸런싱을 수행할 수 있음을 확인할 수 있다.
</p>
