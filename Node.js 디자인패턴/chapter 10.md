# Chapter 10 - 확장성과 구조적 패턴

## 1. 어플리케이션 확장에 대한 소개

### 1-1 Node.js 어플리케이션 확장

<p>
    일반적인 Node.js 어플리케이션의 대부분의 작업이 싱글 스레드의 컨텍스트에서 실행된다. 논 블로킹 I/O에 의해 완벽하게 활용되는 싱글 스레드는 초당 수백 개의 짧은 요청을 처리하는 어플리케이션에 유용하다. 상용 하드웨어를 사용한다고 가정하면 싱글 스레드가 지원할 수 있는 용량은 서버의 성능에 관계없이 제한적이다. 따라서 부하가 많은 어플리케이션에 Node.js를 사용하려는 경우 유일한 방법은 멀티 프로세스와 멀티 머신에 확장하는 것이다.
</p>

<p>
    확장을 통해 작업량 뿐만 아니라 장애에 대한 가용성과 내성 같은 특성을 얻을 수 있다. 확장성은 어플리케이션의 크기와 복잡성에도 적용할 수 있는 중요한 개념이며, 확장 가능한 아키텍처를 구축하는 것은 소프트웨어 설계 시 또 다른 중요 요소이다.
</p>

### 1-2 확장성의 세 가지 차원

<p>
    확장성에서 필요한 첫 번째 기본 원칙은 멀티 프로세스와 멀티 시스템으로 어플리케이션의 부하를 분할하는 부하 분산(load distribution)이다. 이를 달성하는 방법으로 'The Art of Scalability'라는 저서에서는 스케일 큐브(Scale Cube)라고 하는 독창적인 모델을 제시한다. 이 모델은 다음 세 가지 측면에서 확장성을 설명한다.
</p>

- x축: 복제
- y축: 서비스/기능별 분해
- z축: 데이터 파티션 분할

![1](https://user-images.githubusercontent.com/38815618/106353007-b9af9400-632a-11eb-87ce-bc93a8c16eef.PNG)

<p>
    큐브의 왼쪽 아래 모서리는 모든 기능과 서비스를 단일 코드 베이스로한, 단일 인스턴스에서 실행되는 어플리케이션을 나타낸다. 이는 작은 작업량을 처리하거나 개발 초기 단계의 어플리케이션에 공통적인 상황이다.
</p>

<p>
    x축을 따라 확장하는 것은 간단하고 저렴하며 매우 효과적이다. 이 기술 이면의 원리는 동일한 어플리케이션을 n번 복제하고 각 인스턴스가 작업량의 1/n씩을 처리하도록 하는 것이다.
</p>

<p>
    y축을 따라 확장하면 해당 기능, 서비스 또는 유스케이스에 따라 어플리케이션이 분해된다. 이 경우 분해(decomposing)는 각기 다른 코드 베이스가 있는 다른 독립 실행형 어플리케이션을 생성하는 것을 의미하며, 때로는 전용 데이터베이스 또는 별도의 UI를 사용하여 생성하기도 한다. 어플리케이션을 기능별로 분리하는 기준은 주로 비즈니스 요구 사항, use case, 데이터 및 기타 여러 요소에 따라 다르다. 이는 어플리케이션의 아키텍처뿐만 아니라 개발 관점에서 관리되는 방식에도 큰 영향을 미치는 확장성(scale)에 대한 또 하나의 관점이다.
</p>

<p>
    z축을 따라 확장하는 것은 어플리케이션의 각 인스턴스를 전체 데이터의 일부의 처리만을 담당하도록 분할하는 것이다. 이는 주로 데이터베이스에서 사용되는 기술이며 수평 분할 또는 샤딩(sharding)이라 불린다. 이 설정에서는 동일한 어플리케이션의 인스턴스가 여러 개 있으며, 각 인스턴스는 서로 다른 기준을 사용하여 결정되는 데이터 파티션에서 작동한다. 데이터 파티션을 사용하려면 어플리케이션의 어느 인스턴스가 주어진 데이터를 담당하는지 결정하기 위해 각 작업 앞에 조회 단계가 있어야 한다. 데이터 파티셔닝(partitioning)은 대개 거대한 단일 데이터셋을 처리하는 것과 관련한 문제를 극복하기 때문에 데이터베이스 단에서 적용되고 처리된다. 어플리케이션 수준에서 이를 적용하는 것은 복잡하고 분산된 아키텍처 또는 매우 특별한 사용 사례에 대해서만 고려해 볼 가치가 있다. 복잡성을 감안할 때, z축을 따라 확장하는 것은 x, y축을 완전히 활용한 후에만 고려해야 한다.
</p>

## 2. 복제 및 로드 밸런싱

<p>
    전통적으로 멀티스레드 웹 서버는 일반적으로 시스템에 할당된 자원을 더 이상 업그레이드할 수 없거나, 단순히 다른 시스템을 도입하는 것보다 업그레이드에 더 많은 비용이 소요될 경우 확장된다. 멀티스레드를 사용함으로써 기존 웹 서버는 사용 가능한 모든 프로세서와 메모리를 사용하여 서버의 모든 처리 성능을 활용할 수 있다. 하지만 단일 Node.js 프로세스는 싱글스레드로 실행되고, 기본적으로 64비트 시스템에서는 1.7GB의 메모리 제한이 있다. 즉, Node.js 어플리케이션은 일반적으로 단일 시스템의 컨텍스트에서 조차 기존 웹 서버와 비교하여 모든 자원을 활용할 수 있도록 하기 위해 훨씬 빠르게 확장의 필요성이 대두된다.
</p>

<p>
    복제로 Node.js 어플리케이션을 확장하는 것은 비교적 간단해서 중복된 장애 방지 설정을 위해 더 많은 리소스를 확보할 필요가 없는 경우에도 구현되는 경우가 많다.
</p>

<p>
    이렇게 하면 개발자가 어플리케이션의 초기 단계에서 확장성을 고려하게 되어 어플리케이션이 여러 프로세스 또는 시스템에서 공유될 수 없는 리소스에 의존하지 않게 된다. 실제로 어플리케이션을 확장하기 위한 절대적인 전제 조건은 각 인스턴스가 공유할 수 없는 자원에 콩통 정보를 저장할 필요가 없어야 한다는 것이다.
</p>

### 2-1 클러스터 모듈

![1](https://user-images.githubusercontent.com/38815618/106360144-2b530680-635a-11eb-95b5-a5317a397fd4.PNG)

<p>
    Node.js에서 단일 시스템에서 실행되는 여러 개의 인스턴스 간에 어플리케이션의 부하를 분배하는 가장 간단한 패턴은 코어 라이브러리의 일부인 클러스터 모듈을 사용하는 것이다. 클러스터 모듈은 다음 그림과 같이 동일한 어플리케이션의 새 인스턴스를 간단하게 포킹(forking)하고 들어오는 연결을 자동으로 여러 인스턴스에 분산시킨다.
</p>

<p>
    마스터 프로세스는 확장하고자 하는 각 어플리케이션의 인스턴스를 나타내는 여러 프로세스를 생성한다. 들어오는 각 연결은 복제된 작업자들에게 나뉘어져 부하를 분산시킨다.
</p>

#### 클러스터 모듈의 동작에 대한 참고 사항

<p>
    Node.js 0.8 및 0.10 미만에서는 클러스터 모듈이 작업자 간에 동일한 서버 소켓을 공유하고 사용 가능한 작업자 간에 들어오는 연결의 로드 밸런싱 작업을 운영체제에 맡긴다. 이러한 방식은 사실, 운영체제가 작업자에게 부하를 분산시키기 위해 사용하는 알고리즘은 네트워크 요청을 로드 밸런싱하는 것이 아니라 프로세스의 실행을 예약하는 것이다. 결과적으로, 부하가 모든 인스턴스에 걸쳐 항상 균일하지 않다. 대개 일부 작업자가 대부분의 부하를 받는다. 이러한 유형의 동작은 서로 다른 프로세스 사이의 컨텍스트 전환을 최소화하는데 초점을 맞추기 때문에 운영체제 스케줄러에게는 적합할 수 있다. 간단히 말해 클러스터 모듈은 최대한의 잠재력을 발휘하지 못한다.
</p>

<p>
    이후의 버전에서는 명시적 라운드 로빈 로드 밸런스 알고리즘이 마스터 프로세스 내부에 포함되어 요청이 모든 작업자들에게 균등하게 배분된다. 새로운 로드 밸런스 알고리즘은 기본적으로 windows를 제외한 모든 플랫폼에서 사용 가능하다.
</p>

#### 간단한 HTTP 서버 만들기

```javascript
// app.js
const http = require('http');
const pid = process.pid;

http.createServer((req, res) => {
    for (let i = 1e7; i > 0; i--) {}
    console.log(`Handling request from ${pid}`);
    res.end(`Hello from ${pid}\n`);
}).listen(8080, () => {
    console.log(`Started ${pid}`);
});
```

<p>
    HTTP 서버는 PID가 포함된 메시지를 다시 전송하여 모든 요청에 응답한다. 이는 어떤 어플리케이션 인스턴스가 요청을 처리하는지 확인하는데 유용할 것이다. 또한 실제 CPU 작업을 시뮬레이션하기 위해 빈 루프를 천만번 수행한다. 이를 실행하고 네트워크 벤치마킹 도구를 사용하여, 서버가 하나의 프로세스만 사용하여 처리할 수 있는 초당 요청양을 측정할 수 있다.
</p>

#### 클러스터 모듈을 사용한 확장

```javascript
// clusteredApp.js
const cluster = require('cluster');
const os = require('os');

if(cluster.isMaster) {
    const cpus = os.cpus().length;
    for (let i = 0; i < cpus; i++) { // 1.
        cluster.fork();
    }
} else {
    require('./app'); // 2.
}
```

1. 커맨드 라인에서 clusteredApp을 실행하면 마스터 프로세스가 실행된다. cluster.isMaster 변수는 true로 설정되어 있으며 `cluster.fork()`를 사용하여 현재 프로세스를 포킹해야 한다. 앞의 예제에서 사용 가능한 처리 성능을 모두 활용하기 위해 시스템 CPU 수만큼 작업자를 실행한다.
2. 마스터 프로세스에서 `cluster.fork()`를 실행하면 현재 메인 모듈이 다시 실행되지만 이번에는 작업자 모드로 실행된다. 어플리케이션이 작업자로 실행되면 실제 작업을 시작할 수 있다. 이 예제에서는 실제로 새로운 HTTP 서버를 시작하는 app 모듈을 로드한다.

<p>
    이를 실행하면 각 요청에 대해 다른 PID를 가진 메시지를 반환한다. 즉, 요청이 다른 작업자에 의해 처리되어 부하가 분산되었다. 이렇게 하면 멀티 프로세스에서 어플리케이션을 확장하여 얻는 성능 향상을 발견할 수 있다. 만약 4개의 프로세서가 있는 리눅스 시스템에서 Node.js 6을 사용하면 평균 CPU 로드가 90%로 성능 향상이 약 3배가 된다.
</p>

#### 클러스터 모듈을 통한 복원성 및 가용성

<p>
    어플리케이션을 확장하는 것은 특히 오작동이나 갑작스러운 정지가 발생하는 상황에서도 일정한 수준의 서비스를 유지하는 능력과 같은 다른 이점을 가져올 수 있다. 이 속성을 복원성이라고 하며 시스템 가용성에 기여한다.
</p>

<p>
    동일한 어플리케이션의 여러 인스턴스를 시작함으로써 중복 시스템을 생성한다. 즉, 어떤 이유로든 하나의 인스턴스가 중단되더라도 요청을 처리할 수 있는 다른 인스턴스가 여전히 준비되어 있음을 의미한다.
</p>

<p>
    예제를 위해 app.js에 setTimeout과 Error 객체를 이용하여 일정 시간 후에 정지하도록 수정한다. 그 뒤 클러스터 모듈을 사용하여 작업자가 오류 코드로 종료되는 것을 감지하는 새로운 작업자를 생성한다.
</p>

```javascript
if (cluster.isMaster) {
    // ...

    cluster.on('exit', (worker, code) => {
        if (code != 0 && !worker.suicide) {
            console.log('Worker crashed. Starting a new worker');
            cluster.fork();
        }
    });
} else {
    require('./app');
}
```

<p>
    위의 코드는 마스터 프로세스가 exit 이벤트를 받자마자 프로세스가 의도적으로 종료되었는지, 에러로 종류되었는지 확인한다. 오류로 프로세스가 종료되었다면 새로운 작업자를 시작한다. 갑자기 종료된 작업자가 다시 시작되는 동안 다른 작업자가 요청을 계속 처리할 수 있으므로 어플리케이션의 가용성에는 영향을 미치지 않는다.
</p>

#### 다운타임이 없는(Zero-downtime) 재시작

<p>
    Node.js 어플리케이션 코드를 업데이트하면 다시 시작해야 할 수도 있다. 따라서  여러 인스턴스를 사용하면 어플리케이션의 가용성을 유지하는데 도움이 될 수 있다. 의도적으로 어플리케이션을 다시 시작하여 업데이트해야 할 경우, 다시 시작되고 요청을 처리할 수 없는 짧은 간격이 발생한다. 이에 해결책은 어플리케이션의 코드가 가용성에 영향을 미치지 않고 업데이트되도록 다운타임이 없는 재시작을 구현하는 것이다.
</p>

```javascript
// clusterApp.js

// ...

if (cluster.isMaster) {
  // ...
  
    process.on('SIGUSR2', () => { // 1.
        console.log('Restarting workers');
        const workers = Object.keys(cluster.workers);
        
        function restartWorker(i) { // 2.
            if (i >= workers.length) return;
            const worker = cluster.workers[workers[i]];
            console.log(`Stopping worker: ${worker.process.pid}`);
            worker.disconnect(); // 3.
            
            worker.on('exit', () => {
                if (!worker.suicide) return;
                const newWorker = cluster.fork(); // 4.
                newWorker.on('listening', () => {
                    restartWorker(i + 1); // 5.
                });
            });
        }
        restartWorker(0);
    });
} else {
    require('./app');
}
```

1. 작업자의 재시작은 SIGUSR2 시그널 수신 시 시작된다.
2. `restartWorker()`라는 반복 함수를 정의한다. 이는 cluster.workers 객체의 항목에 대해 비동기 순차 반복 패턴을 사용하여 구현한다.
3. `restartWorker()` 함수의 첫 번째 작업은 `worker.disconnect()`를 호출하여 작업자를 정상적으로 중지하는 것이다.
4. 종료된 프로세스가 제거되면 새로운 작업자를 생성할 수 있다.
5. 새로운 작업자가 준비되고 새로운 연결에 대한 listen이 준비되면, 반복의 다음 단계를 호출하여 다음 작업자를 재시작하는 작업을 계속적으로 진행한다.

### 2-2 상태 저장 통신(stateful communication) 다루기

<p>
    어플리케이션에 의해 유지되는 상태가 다양한 인스턴스 간에 공유되지 않는 상태 저장(stateful) 통신에서는 클러스터 모듈이 제대로 동작하지 않는다. 이는 동일한 상태 저장 세션에 속하는 다른 요청이 다른 어플리케이션 인스턴스에 의해 처리될 수 있기 때문이다.
</p>

![1](https://user-images.githubusercontent.com/38815618/106413964-c9e08400-648e-11eb-9772-2a22dac345a2.PNG)

<p>
    사용자 John은 처음에 어플리케이션에 자신을 인증해달라고 요청을 보내지만, 자신의 결과가 로컬(예: 메모리)에 저장된다. 따라서 인증 요청(인스턴스 A)을 받는 어플리케이션의 인스턴스에서만 John이 성공적으로 인증한 것을 인식하게 된다. John이 새로운 요청을 보내면 로드 밸런서는 이를 John의 인증 정보가 없는 다른 어플리케이션 인스턴스로 요청을 전달할 수 있으므로, 작업의 수행이 거부된다. 이를 해결하기 위해 적용할 수 있는 간단한 두 가지 솔루션이 있다.
</p>

#### 여러 인스턴스에서의 상태 공유

<p>
    상태 저장 통신을 사용하여 어플리케이션을 확장해야 하는 첫 번째 옵션은 모든 인스턴스에서 상태를 공유하는 것이다. 이러한 기능은 PostgreSQL, MongoDB 또는 CouchDB와 같은 공유 데이터베이스 저장소를 사용하여 쉽게 얻을 수 있다.
</p>

![2](https://user-images.githubusercontent.com/38815618/106413967-cb11b100-648e-11eb-8168-dacf9aa6cf7e.PNG)

<p>
    공유 저장소를 통신 상태의 저장에 사용할 때 유일한 단점은 항상 가능하지 않다는 것이다. 예를 들어, 메모리에 통신 상태를 저장하는 기존의 라이브러리를 계속 사용해야 하는 상황에 있을 수 있다. 어쨌든 기존의 어플리케이션이 있는 경우 이 솔루션을 적용하려면 어플리케이션의 코드를 변경해야 한다.
</p>

#### 고정 로드 밸런싱

<p>
    상태 저장 통신을 지원하기 위해 필요한 다른 대안은 로드 밸런사가 항상 세션과 관련된 모든 요청을 동일한 어플리케이션 인스턴스로 라우팅하도록 하는 것이다. 이 기술은 고정 로드 밸런싱(sticky load balancing)이라고도 한다.
</p>

![3](https://user-images.githubusercontent.com/38815618/106413968-cbaa4780-648e-11eb-9f75-02ab3e06753c.PNG)

<p>
    로드 밸런서는 새로운 세션과 관련된 요청을 받으면 로드 밸런싱 알고리즘에 의해 선택된 특정 인스턴스와의 맵을 만든다. 다음 번에 로드 밸런서가 동일한 세션에서 요청을 수신하면 이전에 세션과 연관된 어플리케이션 인스턴스를 선택하여 로드 밸런싱 알고리즘을 무시한다.
</p>

<p>
    상태 저장 연결을 하나의 서버에 연결하는 더 간단한 방법은 요청을 수행하는 클라이언트의 IP 주소를 사용하는 것이다. 일반적으로 IP는 요청을 수신하도록 지정된 어플리케이션 인스턴스를 나타내는 ID를 생성하기 위해 해시 함수에 전달된다. 이 기술은 로드 밸런서가 연결을 기억하지 않아도 되는 장점이 있다. 하지만 IP를 자주 변경하는 장치와는 제대로 작동하지 않는다.
</p>

<p>
    고정 로드 밸런싱의 가장 큰 문제는 어플리케이션의 모든 인스턴스가 동일하고, 한 인스턴스가 작업이 중단되면 다른 인스턴스가 이를 대체할 경우 시스템 이중화가 가지는 대부분의 장점이 사라진다는 것이다. 이러한 이유로 될 수 있으면 고정 로드 밸런싱을 피하고, 공유 저장소에서 세션 상태를 유지하거나 상태 저장 통신이 전혀 필요하지 않는 어플리케이션을 만드는 것이 선호된다.
</p>

### 2-3 역방향 프록시를 사용하여 확장

<p>
    클러스터 모듈이 Node.js 웹 어플리케이션 확장을 위한 유일한 옵션은 아니다. 사실 고가용성 운용 환경에서는 더 많은 제어와 성능을 제공하는 전통적인 기법이 더 선호되는 경우가 많다.
</p>

<p>
    클러스터를 사용하는 대신 다른 포트나 시스템에서 실행 중인 동일한 어플리케이션의 독립 실행형 인스턴스를 여러 개 시작한 다음, 역방향 프록시(reverse proxy 또는 gateway)를 사용하여 해당 인스턴스에 액세스하여 트래픽을 분산시킬 수 있다. 이 구성에서는 마스터 프로세스가 일련의 작업자들에게 요청을 배분하지 않고, 서로 다른 프로세스로 동일한 시스템에서 실행되거나 네트워크 내의 분산되어 있는 다른 프로세스들에 요청을 배포한다. 어플리케이션에 단일 액세스 지점을 제공하기 위해 역방향 프록시를 사용할 수 있다. 역방향 프록시는 클라이언트와 어플리케이션의 인스턴스 사이에 위치한 특수 디바이스 혹은 서비스로 모든 요청을 받아 대상 서버에 전달하고, 그 결과를 클라이언트에 반환한다. 이 시나리오에서 역방향 프록시는 어플리케이션 인스턴스 간에 요청을 분산시키는 로드 밸런서로도 사용된다.
</p>

![4](https://user-images.githubusercontent.com/38815618/106413969-cbaa4780-648e-11eb-85a7-954bb00d8db2.PNG)

<p>
    Node.js 어플리케이션에서 cluster 모듈 대신 이 방법을 선택하는 다음의 이유가 있다.
</p>

- 역방향 프록시는 여러 프로세스뿐만 아니라, 여러 시스템에 부하를 분산시킬 수 있다.
- 시장에서 인기있는 역방향 프록시는 대부분 고정 로드 밸런싱을 지원한다.
- 역방향 프록시는 프로그래밍 언어 또는 플랫폼에 관계없이 들어온 요청을 사용 가능한 서버로 라우팅할 수 있다.
- 보다 강력한 로드 밸런싱 알고리즘을 선택할 수 있다.
- 많은 역 프록시들이 URL 재작성, 캐싱, SSL 종단점과 같은 다른 서비스들을 제공하며, 심지어 정적 파일을 서비스하는데 사용될 수 있는 완전한 웹 서버의 기능도 제공한다.

<p>
    필요한 경우 클러스터 모듈을 역방향 프록시와 쉽게 결합할 수 있다. 역방향 프록시를 사용하는 로드 밸런서를 구현하는데는 여러 가지 옵션이 있으며, 일반적인 해결 방법은 다음과 같다.
</p>

- Nginx: 비 차단 I/O 모델을 기반으로 구축된 웹 서버, 역방향 프록시 및 로드 밸런서이다.
- HAProxy: TCP/HTTP 트래픽
- Node.js 기반 프록시: Node.js로 역방향 프록시와 로드 밸런서를 직접 구현할 수 있는 수 많은 방법이 있다.
- 클라우드 기반 프록시: 클라우드 컴퓨팅 시대에 서비스 형 로드 밸런서를 활용하는 것이 드문 일은 아니다. 이는 유지 관리가 거의 필요 없으며, 확장성이 매우 뛰어나고, 주문형 확장을 위한 동적 구성을 지원할 수 있다.

#### Nginx로 로드 밸런싱하기

<p>
    서버의 여러 인스턴스를 시작하는데 클러스터를 사용하지 않으므로, 커맨드 라인을 통해 수신 대기 포트를 인자로 받아들여 지정할 수 있도록 어플리케이션의 코드를 수정해야 한다.
</p>

```javascript
const http = require('http');
const pid = process.pid;

http.createServer((req, res) => {
    for (let i = 1e7; i > 0; i--) {}
    console.log(`Handling request from ${pid}`);
    res.end(`Hello from ${pid}\n`);
}).listen(process.env.PORT || process.argv[2] || 8080, () => {
    console.log(`Started ${pid}`);
});
```

<p>
    클러스터를 사용하지 않을 경우 부족한 또 다른 중요한 기능은 충돌이 발생할 경우 자동으로 다시 시작하는 것이다. 이는 어플리케이션을 모니터링하고 필요한 경우 재시작하는 외부 프로세스인 전용 수퍼바이저를 사용하여 쉽게 해결할 수 있다. 이를 위한 항목은 다음과 같다.
</p>

- Node.js 기반의 수퍼바이저인 forever 또는 pm2
- OS 기반의 모니터 upstart 또는 runit
- monit 또는 supervisor

<p>
    해당 예제를 위해 forever를 사용한다. 다음은 어플리케이션의 4개 인스턴스를 모두 다른 포트에서 시작하고 forever로 감시하는 것이다.
</p>

```bash
forever start app.js 8081
forever start app.js 8082
forever start app.js 8083
forever start app.js 8084
```

<p>
    Ngix 서버를 로드 밸런서로 설정하기 위해 ngix.conf를 사용한다.
</p>

```config
http {
    # [...]
    
    upstream nodejs_design_patterns_app {
        server 127.0.0.1:8081;
        server 127.0.0.1:8082;
        server 127.0.0.1:8083;
        server 127.0.0.1:8084;
    }

    # [...]
    
    server {
        listen 80;

        location / {
            proxy_pass http://nodejs_design_patterns_app;
        }
    }
    
    # [...]
}
```

<p>
    코드의 upstream nodejs_design_patterns_app 영역에서 네트워크 요청을 처리하는데 사용되는 백엔드 서버 목록을 정의한 다음 server 영역에서 proxy_pass를 지정한다. 이 지정문은 기본적으로 Nginx에게 정의한 서버 그룹에 요청을 전달하도록 한다.
</p>

### 2-4 서비스 레지스트리(service registry)

<p>
    최신 클라우드 기반 인프라의 한 가지 중요한 이점은 현재 또는 예측된 트래픽을 기반으로 어플리케이션의 용량을 동적으로 조정할 수 있다는 것이다. 이를 동적 스케일링(dynamic scaling)이라고 한다. 이러한 방식은 어플리케이션의 가용성과 응답성을 유지하면서 IT 이늪라의 비용을 엄청나게 줄일 수 있다.
</p>

<p>
    해당 개념은 어플리케이션의 트래픽이 최고조에 달해 성능의 저하가 발생하면 증가된 부하에 대처하기 위해 새 서버가 자동으로 생성되며, 특정 시간 동안 일부 서버를 종료할 수도 있다. 이 메커니즘을 사용하면 로드 밸런서가 항상 서버가 작동하는 시간을 알기 위해, 현재 네트워크 토폴로지에 대해 최신 상태를 유지해야 한다. 이러한 문제를 해결하기 위한 일반적인 패턴은 실행중인 서버와 해당 서버가 제공하는 서비스를 추적하는 서비스 레지스트리라는 중앙 저장소를 사용한다.
</p>

![1](https://user-images.githubusercontent.com/38815618/106561831-c4596b80-656c-11eb-966a-a83e8a4b2616.PNG)

<p>
    위 아키텍처는 API와 WebAp 두 가지 서비스가 있다고 가정한다. 로드 밸런서는 엔드포인트인 /api에 도착하는 요청들을 API 서비스를 구현한 모든 서버에 분배하고, 나머지 요청들은 WebApp 서비스를 구현한 서버에 분산시킨다. 로드 밸런서는 레지스트리를 사용하여 서버 목록을 얻게 된다.
</p>

<p>
    각 어플리케이션 인스턴스는 각자 온라인이 되는 순간에 자신을 서비스 레지스트리에 등록하고 중단될 때는 등록을 취소해야 한다. 이렇게 하면 로드 밸런서는 항상 네트워크에서 사용할 수 있는 서버 및 서비스에 대한 최신 정보를 가질 수 있다. 이 패턴은 로드 밸런싱 뿐만 아니라, 더 일반적으로는 서버에서 제공하느 서비스 유형을 분리하는 방법으로도 사용할 수 있다.
</p>

#### http-proxy와 consul을 사용한 동적 로드 밸런싱 구현

<p>
    Node.js 만을 사용하여 로드 밸런서를 구축하면 훨씬 더 많은 자유와 성능을 얻을 수 있으며, 서비스 레지스트리를 포함한 사용자 정의 로드 밸런싱 장치에 어떠한 유형의 패턴이나 알고리즘도 바로 구현할 수 있다. 다음 예제는 클러스터와 Nginx를 터스트하기 위해 사용한 것과 같은 간단한 HTTP 서버지만, 이번에는 각 서버가 시작하는 순간 서비스 레지스트리에 등록한다.
</p>

```javascript
// app.js
const http = require('http');
const pid = process.pid;
const consul = require('consul')();
const portfinder = require('portfinder');
const serviceType = process.argv[2];

portfinder.getPort((err, port) => { // 1.
    const serviceId = serviceType+port;
    consul.agent.service.register({ // 2.
        id: serviceId,
        name: serviceType,
        address: 'localhost',
        port: port,
        tags: [serviceType]
    }, () => {

        const unregisterService = (err) => { // 3.
            consul.agent.service.deregister(serviceId, () => {
                process.exit(err ? 1 : 0);
            });
        };

        process.on('exit', unregisterService); // 4.
        process.on('SIGINT', unregisterService);
        process.on('uncaughtException', unregisterService);

        http.createServer((req, res) => { // 5.
            for (let i = 1e7; i > 0; i--) {}
            console.log(`Handling request from ${pid}`);
            res.end(`${serviceType} response from ${pid}\n`);
        }).listen(port, () => {
            console.log(`Started ${serviceType} (${pid}) on port ${port}`);
        });
    });
});
```

- http-proxy: Node.js에 프록시와 로드 밸런서를 간단하게 생성할 수 있는 라이브러리
- portfinder: 시스템의 빈 포트를 발견할 수 있는 라이브러리
- consul: 서비스 등록을 허용하는 라이브러리

1. 먼저 portfinder.getPort를 사용하여 시스템의 빈 포트를 찾는다(기본적으로 8000부터 검색).
2. 다음으로 Consul 라이브러리를 사용하여 레지스트리에 새 서비스를 등록한다. 서비스 정의에는 id, name, address와 port, tag같은 일련의 속성이 필요하다. 이렇게 하면 cluster에서 사용할 수 있는 동일한 유형의 모든 서비스를 식별할 수 있다.
3. 여기서 Consul에 방금 등록한 서비스를 제거할 수 있는 unregisterService라는 함수를 정의한다.
4. unregisterService를 정리를 위한 함수로 사용하여 프로그램이 닫힐 때 서비스가 Consul에서 등록 해지되도록 한다.
5. 마지막으로 portfinder가 발견한 포트에서 서비스를 위한 HTTP 서버를 시작한다.

```javascript
// loadBalancer.js - 1
const routing = [
  {
    path: '/api',
    service: 'api-service',
    index: 0
  },
  {
    path: '/',
    service: 'webapp-service',
    index: 0
  }
];
```

<p>
    위의 코드는 먼저 uRL 경로를 서비스에 매핑하는 라우팅 테이블을 정의하였다. 라우팅 배열의 각 항목에는 매핑된 경로로 들어오는 요청을 처리하는데 사용되는 서비스가 포함되어 있다. index 속성은 지정된 서비스의 요청을 라운드 로빈하는데 사용된다.
</p>

```javascript
// loadBalancer.js - 2
const http = require('http');
const httpProxy = require('http-proxy');
const consul = require('consul')(); // 1.

const proxy = httpProxy.createProxyServer({});
http.createServer((req, res) => {
    let route;
    routing.some(entry => { // 2.
        route = entry;
        // route path를 시작하는지 체크
        return req.url.indexOf(route.path) === 0;
    });

    consul.agent.service.list((err, services) => { // 3.
        const servers = [];
        Object.keys(services).filter(id => {
            if (services[id].Tags.indexOf(route.service) > -1) {
                servers.push(`http://${services[id].Address}:${services[id].Port}`)
            }
        });

        if (!servers.length) {
            res.writeHead(502);
            return res.end('Bad gateway');
        }

        route.index = (route.index + 1) % servers.length; // 4.
        proxy.web(req, res, {target: servers[route.index]});
    });
}).listen(8080, () => console.log('Load balancer started on port 8080'));
```

1. 레지스트리에 접근하기 위해 consul을 불러온다. 다음으로 http-proxy 객체를 인스턴스화하고 일반 웹 서버를 시작한다.
2. 서버의 요청 핸들러에서 가장 먼저 수행해야 할 작업은 URL을 라우팅 테이블과 비교하는 것이다. 결과는 서비스 이름을 포함하는 기술자(descriptor)가 된다.
3. Consul로부터 필요한 서비스가 구현된 서비스들의 목록을 얻는다. 만약 이 목록이 비어있으면 클라이언트에 에러를 반환한다. tag 속성을 사용하여 사용 가능한 모든 서비스에서 현재 서비스 유형을 구현한 서버의 주소를 찾는다.
4. 끝으로 요청을 목적지로 라우팅한다. 라운드 로빈 방식에 따라 route.index를 목록의 다음 서버를 가리키도록 업데이트한다. 그런 다음 인덱스를 사용하여 목록에서 서버를 선택하여 요청 및 응답 개체와 함께 `proxy.web()`으로 전달한다. 그러면 선택한 서버로 요청이 전달된다.

<p>
    이 패턴의 장점은 즉각적이라는 것이다. 피룡에 따라 또는 일정에 따라 인프라를 동적으로 바로 확장할 수 있으며, 로드 밸런서는 별도의 추가 작업 없이 새로운 구성에 따라 자동으로 조정된다.
</p>

### 2-5 피어-투-피어 로드 밸런싱(peer-to-peer load balancing)

<p>
    역방향 프록시의 사용은 복잡한 내부 네트워크 아키텍쳐를 인터넷과 같은 공용 네트워크 영역에 공개하고자 할 때 거의 필수적이다. 복잡성을 숨기고 외부 어플리케이션이 쉽게 사용하고 참조할 수 있는 유일한 접근점을 제공한다. 그러나 내부용으로만 서비스를 확장해야 하는 경우 더 많은 유연성과 제어 기능을 제공할 수 있다.
</p>

<p>
    이러한 기능을 구현하기 위해 서비스 B에 의존하는 서비스 A가 있다고 가정해보면, 서비스 B는 여러 컴퓨터에 걸쳐 확장되며 내부 네트워크에서만 사용할 수 있다. 지금까지 배웠던 것은 서비스 A가 서비스 B를 구현하는 모든 서버에 트래픽을 배분하는 역방향 프록시를 사용하여 서비스 B에 연결한다는 것이다.
</p>

<p>
    이에 대안은 역방향 프록시를 제거하고 요청을 클라이언트에서 직접 배분하는 것이다. Service A는 Service B의 다양한 인스턴스 간의 연결에 대한 로드 밸런싱을 직접 담당한다. 이는 Service A가 Service B의 동작중인 서버에 대한 세부적인 정보를 알고 있고, 내부 네트워크에서 일반적으로 알려진 정보인 경우에만 가능하다. 이 접근 방식은 근본적으로 피어-투-피어 로드 밸런싱을 구현한다.
</p>

![2](https://user-images.githubusercontent.com/38815618/106561836-c58a9880-656c-11eb-89a5-342ba59f96cc.PNG)

<p>
    병목 현상이나 단일 접속점이 실패한 경우에 대한 걱정 없이 진정한 분산 통신을 가능하게 하는 매우 간단하고 효과적인 패턴이다. 또한 다음 이점이 있다.
</p>

- 네트워크 노드를 제거하여 인프라의 복잡성을 줄인다.
- 더 적은 노드를 통해 메시지가 전달되기 때문에 더 빠른 통신이 가능하다.
- 로드 밸런서가 처리할 수 있는 성능으로 인해 성능이 제한되지 않기 때문에 확장성이 좋다.

<p>
    반대로 역방향 프록시를 제거하면 실제로 기본 인프라의 복잡성이 노출된다. 또한 각 클라이언트는 로드 밸런싱 알고리즘을 구현하고 매일 변경될 수도 있는 인프라에 대한 정보를 최신 상태로 유지할 수 있어야 한다.
</p>

#### 여러 서버에 대해 요청을 분산할 수 있는 HTTP 클라이언트 구현

```javascript
// balanceRequest.js
const http = require('http');
const servers = [
    {host: 'localhost', port: '8081'},
    {host: 'localhost', port: '8082'}
];

let i = 0;

module.exports = (options, callback) => {
    i = (i + 1) % servers.length;
    options.hostname = servers[i].host;
    options.port = servers[i].port;
    
    return http.request(options, callback);
};
```

<p>
    위의 코드는 라운드 로빈 알고리즘을 사용하여 사용 가능한 서버 목록에서 선택한 서버에 맞도록 요청의 호스트 이름 및 포트를 재정의하도록 원래 http.request API를 래핑하였다. 그러면 래핑된 API를 다음과 같이 원활하게 사용할 수 있다.
</p>

```javascript
// client.js
const request = require('./balancedRequest');

for (let i = 10; i >= 0; i--) {
    request({method: 'GET', path: '/'}, res => {
        let str = '';
        res.on('data', chunk => {
                str += chunk;
        }).on('end', () => {
            console.log(str)
        });
    }).end();
}
```

<p>
    코드를 실행하기 위해서는 제공된 샘플 서버의 인스턴스 두 개를 시작해야 한다. 어플리케이션을 실행하면 각 요청이 다른 서버로 전송되는 방식을 확인하여 이제 전용 역방향 프록시 없이도 로드 밸런싱을 수행할 수 있음을 확인할 수 있다.
</p>

## 3. 복잡한 어플리케이션 분해

### 3-1 단일(Monolitic) 아키텍처

<p>
    종종 단일(Monolitic) 시스템은 높은 모듈형 구조와 해당 내부 컴포넌트들 사이의 좋은 분할을 가지기도 한다. 예시로 단일 커널(Monolitic Kernels)d이라고 하는범주에 속하는 LinuxOS 커널을 들 수 있다. Linux에는 시스템이 실행되는 동안에도 동적으로 로드하거나 내려놓을 수 있는 수천 개의 서비스와 모듈이 있다. 하지만 이들은 커널 모드에서 실행되므로 이 모드 중 하나에 장애가 발생하면 전체 OS가 중단될 수 있다(커널 패닉이 발생하는 이유이다). 이 접근 방식은 운영체제의 핵심 서비스만 커널 모드로 실행되고, 나머지는 사용자 모드로 실행되는 마이크로 커널 아키텍처와 상반된다. 이 접근 방식의 주요 장점은 이러한 서비스의 문제가 전체 시스템의 안정성에 영향을 미치지 않고, 별도로 격리되어 문제가 발생하게 된다는 것이다.
</p>

<p>
    현재 단일(Monolithic) 어플리케이션은 단일 커널과 유사하다. 컴포넌트 중 하나라도 오류가 발생하면 전체 시스템이 영향을 받는다. 이는 모든 서비스가 동일한 코드 베이스의 일부이며 단일 프로세스에서 실행됨을 의미한다.
</p>

![1](https://user-images.githubusercontent.com/38815618/106690691-9ed46c80-6615-11eb-9b80-395a87fe210f.PNG)

<p>
    위 그림은 일반적인 전자상거래 어플리케이션의 아키텍처를 보여준다. 구조는 모듈 방식으로 두 개의 서로 다른 프론트엔드를 가지고 있다. 내부적으로 어플리케이션에 의해 구현된 서비스는 분명히 분리되어 있으며, 각 서비스는 특정 부분의 비즈니스 로직을 담당한다. 하지만 아키텍처는 모놀리식이며, 실제로 모든 모듈은 동일한 코드 베이스의 일부이고, 단일 어플리케이션의 일부로 실행된다. 따라서 한 컴포넌트의 오류로 온라인 전자상거래 어플리케이션 전체가 손상될 수 있다.
</p>

<p>
    이러한 아키텍처의 또 다른 문제점은 모듈 간의 상호 연결이다. 예를 들어 제품을 구매할 경우에서, CheckOut 모듈은 Product 객체의 상태를 갱신해야 하는데, 두 모듈이 동일한 어플리케이션에 있으면 개발자가 Product 객체의 참조를 쉽게 얻어 상태를 직접 갱신할 수 있다. 단일 어플리케이션에서는 내부 모듈 간의 낮은 결합을 유지하는 것이 매우 어려운데, 이는 모듈 사이의 경계가 항상 명확하거나 적절히 적용되지 않기 때문이다.
</p>

<p>
    높은 결합력(A high Coupling)은 종종 어플리케이션의 성장을 가로막는 주요 장애물 중 하나이며, 복잡성 측면에서 확장성을 저해한다. 복잡성 의존성 그래프는 시스템의 모든 부분이 책임이라는 것을 의미한다. 이는 제품의 전체 수명 동안 유지되어야 하며, 모든 컴포넌트가의 변경 사항을 주의 깊게 평가해야 한다. 어느 한 컴포넌트가 문제가 발생하면 전체가 붕괴될 수 있기 때문이다. 이로 인해 프로젝트의 복잡성이 증가함에 따라 결국 규칙 및 개발 프로세스가 수립되는 경우가 많다.
</p>

### 3-2 마이크로 서비스 아키텍처

<p>
    Node.js에서 가장 중요한 패턴 중 하나는 '큰 어플리케이션을 작성하지 마라'이다. 이는 소프트웨어 시스템의 복잡성과 용량을 확장하는 매우 효과적인 전략이다. 개념은 어플리케이션을 필수 컴포넌트로 분해하여 별도의 독립 어플리케이션으로 만드는 것이다. 모놀리식과는 반대로, '각 프로그램은 한가지 일만을 잘 수행하도록'이라는 원칙에 부합한다.
</p>

<p>
    오늘날 마이크로 서비스 아키텍처는 이러한 유형의 접근 방식의 주요 패턴이며, 일련의 자체 서비스가 대형의 단일 어플리케이션을 대체한다. 마이크로는 서비스가 가능한 작아야 하나, 항상 합리적인 한도 내에 있어야 함을 의미한다. 실 세계에서는 서비스가 얼마나 작아야 하는지, 얼마나 커야 하는지에 대한 엄격한 규칙이 없다. 마이크로 서비스 아키텍처의 설계에서 중요한 것은 크기가 아니다. 대신, 주로 느슨한 결합(loose coupling), 높은 응집력(cohesion), 통합 복잡성(integration complexity)과 같은 다른 요소들의 조합이 중요하다.
</p>

#### 마이크로 서비스 아키텍처의 예

![2](https://user-images.githubusercontent.com/38815618/106690695-a0059980-6615-11eb-946c-0cc819f3264e.PNG)

<p>
    위의 그림처럼 어플리케이션의 각 기본 컴포넌트는 자체적인 데이터베이스를 가지고 자신의 환경에서 동작하는 자립적이고 독립체이다. 실제로 이들은 모두 독립적인 어플리케이션으로 일련의 관련 서비스들을 노출하고 있다.
</p>

<p>
    서비스의 데이터 소유권은 마이크로 서비스 아키텍처의 중요한 특성이다. 따라서 데이터베이스를 분할하여 적절한 격리 및 독립성의 수준을 유지해야 한다. 고유한 공유 데이터베이스를 사용할 경우 서비스가 함께 동작하기가 훨씬 쉬워진다. 그러나, 이는 또한 서로 다른 서비스들 간의 결합(데이터 기반)을 가져와 다른 어플리케이션들의 장점 중 일부를 제거하게 된다.
</p>

<p>
    모든 노드를 연결하는 점선은 전체 시스템이 제대로 동작할 수 있도록 통신과 정보를 주고 받아야 완전한 기능을 수행할 수 있음을 나타낸다. 서비스가 동일한 데이터베이스를 공유하지 않기 때문에 전체 시스템의 일관성을 유지하기 위해 더 많은 통신이 필요하다. 예를 들어 Checkout 어플리케이션은 가격 및 배송 제한과 같은 제품 관련 정보를 알아야 한다. 동시에 Product 서비스에 저장된 데이터, 예를 들자면 계산이 완료된 후 Product의 상태와 같은 정보를 업데이트해야 한다.
</p>

#### 마이크로 서비스의 장단점

##### 모든 서비스는 소모품이다.

<p>
    각 서비스를 자체 어플리케이션의 컨텍스트에서 윤영하는 것의 주요 기술적인 장점은 충돌, 버그 및 변경, 중단이 전체 시스템으로 전파되지 않다는 것이다. 목표는 작고, 변경하기 쉽고 처음부터 다시 빌드할 수 있는 진정한 독립적인 서비스를 구축하는 것이다.
</p>

<p>
    또한, 모놀리식 어플리케이션에서는 전체 시스템에 영향을 미치지 않고 변경하기 어려우나, 마이크로 서비스 아키텍처에서는 다른 데이터베이스나 플랫폼을 사용하여 전체 서비스를 처음부터 쉽게 다시 구현할 수 있다.
</p>

##### 플랫폼 및 언어 전반에서의 재사용성

<p>
    대규모 단일 어플리케이션을 여러 개의 소규모 서비스에 분할하면 훨씬 더 쉽게 재사용할 수 있는 독립적인 유닛을 만들 수 있다. 주된 장점은 단일 어플리케이션에 비해 정보 은닉 수준이 훨씬 높다는 것이다. 이는 일반적인 웹 서비스 또는 메시지 브로커와 같은 원격 인터페이스를 통해 이루어지므로 구현의 세부 정보를 숨기고 클라이언트를 서비스 구현 또는 배포 방식의 변경으로부터 보호하기가 훨씬 용이하다.
</p>

##### 어플리케이션을 확장하는 방법

<p>
    스케일 큐브 관점에서 마이크로 서비스는 y축을 따라 어플리케이션을 확장하는 것과 같다. 따라서 이미 여러 시스템에 부하를 분산시킬 수단이 준비되어 있다. 또한, 마이크로 서비스를 큐브의 다른 두 차원과 결합하여 어플리케이션을 더욱 확장할 수 있다.
</p>

##### 마이크로 서비스의 과제

<p>
    관리해야 할 노드가 많아지면 통합, 배포 및 코드 공유 측면에서 복잡서잉 높아진다. 이는 전통적인 구조들의 일부 문제들을 해결하지만 또한 많은 문제들을 제기한다. 클라우드 서비스와 현대적인 DevOps 방법론은 이러한 문제에 대한 해답을 제공할 수 있으며, Node.js도 많은 도움이 될 수 있다. 모듈 시스템은 다른 프로젝트 간에 코드를 공유하기에 완벽한 동반자이다. Node.js는 마이크로 서비스 아키텍처를 사용하여 구현된 것과 같은 분산 시스템의 노드로 만들어졌다.
</p>

### 3-3 마이크로 서비스 아키텍처의 통합 패턴

<p>
    마이크로 서비스의 가장 어려운 과제 중 하나는 모든 노드를 연결하여 공동 작업을 수행하는 것이다. 통합 전략을 설계할 대는 시스템에서 서비스 간에 가지게 될 커플링(coupling)을 고려하는 것도 중요하다. 분산형 구조를 설계할 때는 모듈이나 서브 시스템을 설계할 대 지역적으로 사용하는 것과 동일한 관행과 원칙을 수반하므로 재사용 가능성과 확장성같은 특성도 고려해야 한다.
</p>

#### API 프록시

<p>
    첫 번째 패턴은 클라이언트와 원격 API 집합 간의 통신을 프록시하는 서버인 API 프록시를 사용하는 것이다. 마이크로 서비스 아키텍처에서 이 아키텍처의 주요 목적은 여러 API 엔드포인트에 대한 단일 접근점을 제공하는 것이지만 로드 밸런싱, 캐싱, 인증 및 트래픽 제한을 제공할 수 있으며, 모든 기능은 견고한 API 솔루션을 구현하는데 매우 유용하다.
</p>

![3](https://user-images.githubusercontent.com/38815618/106690696-a0059980-6615-11eb-97b5-ba2e89c752f4.PNG)

<p>
    위의 그림에서 API 프록시가 어떻게 기반 인프라의 복잡성을 숨길 수 있는지를 알 수 있다. 이는 특히 각 서비스가 여러 시스템으로 확장되는 경우, 노드 수가 많을 수 있으므로 마이크로 서비스 인프라에서 매우 유용하다. 따라서 API 프록시를 통해 이루어지는 통합은 구조적으로만 이루어지며 의미론적인 메커니즘은 없다. 복잡한 마이크로 서비스 인프라에 대한 친숙한 단일(monolithic) 뷰를 제공한다.
</p>

#### API 오케스트레이션(orchestration)

<p>
    넷플릭스 API 담당 엔지니어링 DanielJacobson은 API 오케스트레이션을 다음과 같이 정의한다.
</p>

> "OL(APIOrchestrationLayer)은 일반적으로 모델링된 데이터 요소 혹은 기능을 사용하는 추상화 계층으로, 해당 개발자나 어플리케이션을 위해 구체적인 방법을 마련한다"

<p>
    일반적으로 모델링된 요소나 기능은 마이크로 서비스 아키텍처의 서비스 설명(description)에 완벽하게 부합한다. 이 개념은 어플리케이션과 관련된 새로운 서비스를 구현하기 위해 필요한 요소들에 대한 추상화를 만드는 것이다.
</p>

![4](https://user-images.githubusercontent.com/38815618/106690697-a09e3000-6615-11eb-9911-40daa8cc0dee.PNG)

<p>
    위의 그림에서는 프론트엔드 어플리케이션 Store가 오케스트레이션 계층을 사용하여 기존 서비스를 구성하고 조정하여 보다 복잡하고 구체적인 기능을 만드는 방법을 보여 준다. 설명된 시나리오는 고객이 구매를 마치기 위해 Pay 버튼을 클릭하는 순간 호출되는 가상의 completeCheckout() 서비스를 예로 들고 있다.
</p>

1. 먼저 CheckoutService/Pay를 호출하여 트랜잭션을 완료한다.
2. 그후 다음 지불이 성공적으로 처리되면, cart 서비스에 물품이 구매되었고 카트에서 제거해도 된다고 알려야 한다. 이를 CheckoutService/delete를 호출하여 수행한다.
3. 결제가 완료되면 방금 구입한 제품의 상태를 업데이트해야 한다. 이는 productService/update를 통해 수행된다.

<p>
    API 오케스트레이션 계층에서 수행하는 또 다른 일반적인 작업은 데이터 집계(data aggregation)이다. 즉, 다른 서비스의 데이터를 하나의 응답으로 결합하는 것이다. 예를 들어 장바구니에 담긴 모든 제품을 나열하고 싶다고 한다면, 오케스트레이션은 카트 서비스에서 제품 ID 목록을 검색한 후 제품 서비스에서 제품에 대한 전체 정보를 검색해야 한다. 오케스트레이션 계층의 역활은 여러 서비스와 특정 어플리케이션 간의 추상화 한다.
</p>

![5](https://user-images.githubusercontent.com/38815618/106690700-a09e3000-6615-11eb-9209-974e49ea4622.PNG)

<p>
    위의 그림과 같이 독립형 오케스트레이터를 만들면 클라이언트 어플리케이션과 마이크로 서비스 인프라의 복잡성을 분리할 수 있다. 오케스트레이터는 다양한 서비스의 의미론적 통합을 수행한다. 이는 단순한 프록시가 아니며, 기본 서비스에서 공개된 API와 다른 API를 공개한다.
</p>

#### 메시지 브로커와의 통합

<p>
    오케스트레이터 패턴은 설계, 디버그 및 확장이 쉽지만, 기본 아키텍처와 각 서비스의 동작 방식에 대해 완벽하게 알고 있어야 한다. 구조적인 노드들이 아닌 객체들에 대해 말하는 것이라면 오케스트레이터는 전지정능한 객체(God Object)라 불리는 안티 패턴이 될 것이다. 이 객체는 과도하게 많은 객체를 정의하게 될 것이다. 이는 일반적으로 높은 결합성과 낮은 응집력 그리고 복잡성을 초래하게 된다.
</p>

<p>
    다음은 전체 시스템의 정보를 동기화하는 작업을 서비스 전반에 걸쳐 분산하는 패턴이다. 하지만 하려는 마지막 작업은 서비스 간의 직접적인 관계를 생성하는 것이다. 이는 노드 간의 상호 연결 수의 증가로 인해 높은 커플링을 초래하고 시스템의 복잡성을 더욱 증가시킨다. 따라서 목표는 각 서비스를 격리 상태로 유지하는 것이다. 각 서비스는 시스템의 나머지 서비스 없이도 또는 새로운 서비스 및 노드와 결합하여 작동할 수 있어야 한다.
</p>

<p>
    해결책은 메시지의 수신자와 발신자를 분리할 수 있는 시스템인 메시지 브로커를 사용하여 중앙 집중식 게시(publish)/구독(subscribe) 패턴을 구현하는 것이다. 실제로는 분산 시스템에 대한 관찰자 패턴을 사용한다.
</p>

![6](https://user-images.githubusercontent.com/38815618/106690704-a136c680-6615-11eb-92ab-64054e0b725e.PNG)

<p>
    위의 그림을 보면 프론트엔드 어플리케이션인 체크아웃 서비스의 클라이언트는 다른 서비스와의 명시적 통합을 수행할 필요가 없다. 단지 checkoutService/pay를 호출하여 결제를 완료하고 고객으로부터 돈을 인출하는 것이다.
</p>

1. Store 프론트엔드는 체크아웃 서비스에서 checkoutService/pay 연산을 호출한다.
2. 작업이 완료되면 체크아웃 서비스는 작업의 세부 사항, 즉 cartID 및 방금 구입한 products을 첨부하여 이벤트를 생성한다. 이 이벤트는 메시지 브로커에게 게시된다. 이 시점에서 checkout 서비스는 누가 메시지를 받을 것인지 알 수 없다.
3. 카트 서비스는 브로커에게 구독자로 등록되어 있으므로 체크아웃 서비스에서 방금 게시한 purchased 이벤트를 받게 된다. 카트 서비스는 메시지에 포함된 ID로 식별된 장바구니를 자신의 데이터베이스에서 제거함으로써 반응한다.
4. 제품 서비스는 메시지 브로커에도 가입되어 있으므로 동일한 구매 이벤트를 받는다. 그런 다음 이 정보를 기반으로 데이터베이스를 업데이트하여 메시지에 포함된 제품의 정보를 갱신한다.

<p>
    전체 프로세스는 오케스트레이터와 같은 외부 개체에서 명시적으로 개입하지 않아도 발생한다. 정보를 전파하고 정보를 동기화하는 책임은 서비스 자체에 분산된다. 전체 시스템 동작을 관할하고 알고 있어야 하는 전지전능한 서비스는 존재하지 않는다. 각 서비스는 자체적으로 통합을 담당한다.
</p>

<p>
    메시지 브로커는 서비스를 분리하고 서비스 상호작용의 복잡성을 줄이기 위한 기본 요소이다. 또한 영구 메시지 큐 및 보장된 메시지 순서와 같은 다른 흥미로운 기능을 제공할 수도 있다.
</p>
